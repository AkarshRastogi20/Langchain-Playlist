{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Create requirement.txt file**"
      ],
      "metadata": {
        "id": "aT8CvKhY0vdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write content to a text file\n",
        "with open('requirements.txt', 'w') as f:\n",
        "    f.write(\"\"\"\n",
        "    langchain\n",
        "    streamlit\n",
        "    openai\n",
        "    huggingface_hub\n",
        "    python-dotenv\n",
        "    streamlit\"\"\") # using triple double inverted comma for mutiple entries"
      ],
      "metadata": {
        "id": "Eygldmhm00pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Working on ipynb file**"
      ],
      "metadata": {
        "id": "6_Sh3i0x7dp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "import os\n",
        "os.environ['OPEN_AI_API_KEY']=\"sk-proj-ZlvuERRBPh05EY9f6NDYT3BlbkFJ8gQCYk2vAhkvYunitJgT\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jLvpOnB7cfF",
        "outputId": "63099caa-52be-46a1-dfb1-70023d788586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.44 langchain-text-splitters-0.0.1 langsmith-0.1.49 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install OpenAI\n",
        "llm=OpenAI(openai_api_key=os.environ[\"OPEN_AI_API_KEY\"],temperature=0.6) # the more value of the temperature towards 1 the more your model will be creative"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFpKBSBF4kFi",
        "outputId": "d7d3b7ff-796a-488d-c7b1-08ac950137a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting OpenAI\n",
            "  Downloading openai-1.23.1-py3-none-any.whl (310 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/311.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.6/311.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from OpenAI) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from OpenAI)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from OpenAI) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from OpenAI) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->OpenAI) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->OpenAI) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->OpenAI)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->OpenAI)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->OpenAI) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, OpenAI\n",
            "Successfully installed OpenAI-1.23.1 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"What is the capital of india\"\n",
        "print(llm.predict(text))  # Not running because of money, Here we are working with open ai"
      ],
      "metadata": {
        "id": "KgLUdWxA9TN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"Here we have to mention token code\" # It is asking for money"
      ],
      "metadata": {
        "id": "3N5xRsQb1-k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub"
      ],
      "metadata": {
        "id": "5ruiBwCI2t-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\",model_kwargs={\"temperature\":0,\"max_length\":64}) # when search for model on hugging face you will get it as a title\n",
        "#max string length will be 64"
      ],
      "metadata": {
        "id": "VbVJZQldaQ0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output=llm_huggingface.predict(\"Can you tell me the capital of Russia\")\n",
        "print(output) # here we are working with hugging face"
      ],
      "metadata": {
        "id": "-e1M9wKJbra0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Templates and LLMChain**"
      ],
      "metadata": {
        "id": "fCY4zFO7dDgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template=PromptTemplate(input_variables=['country'],\n",
        "template=\"Tell me the capital of this {country}\")\n",
        "\n",
        "prompt_template.format(country=\"India\")"
      ],
      "metadata": {
        "id": "3f1OFneLfA7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "Zq_BV3c4fq82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain=LLMChain(llm=llm,prompt=prompt_template)\n",
        "chain.run(\"India\")"
      ],
      "metadata": {
        "id": "buLD4NP4f4-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Combining Multiple chains using simple Sequential chain**"
      ],
      "metadata": {
        "id": "PHndnvtUiLKT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "capital_prompt=PromptTemplate(input_variables=['country'],\n",
        "template=\"Please tell me the capital of {country}\") # 1 template\n",
        "\n",
        "capital_chain=LLMChain(llm=llm,prompt=capital_prompt)\n",
        "\n",
        "famous_template=PromptTemplate(input_variables=['capital'],\n",
        "template=\"Suggest me some amazing places to visit in {capital}\") # 2 template\n",
        "\n",
        "famous_chain=LLMChain(llm=llm,prompt=famous_template)\n",
        "\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "chain=SimpleSequentialChain(chains=[capital_chain,famous_chain])\n",
        "chain.run(\"India\")"
      ],
      "metadata": {
        "id": "xQjcx8XPiZ4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential Chain**"
      ],
      "metadata": {
        "id": "_0EYCAj1mHvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "capital_prompt=PromptTemplate(input_variables=['country'],\n",
        "template=\"Please tell me the capital of {country}\") # 1 template\n",
        "\n",
        "capital_chain=LLMChain(llm=llm,prompt=capital_prompt,output_key=\"capital\")\n",
        "\n",
        "famous_template=PromptTemplate(input_variables=['capital'],\n",
        "template=\"Suggest me some amazing places to visit in {capital}\") # 2 template\n",
        "\n",
        "famous_chain=LLMChain(llm=llm,prompt=famous_template,output_key=\"places\")\n",
        "\n",
        "from langchain.chains import SequentialChain\n",
        "chain=SequentialChain(chains=[capital_chain,famous_chain],\n",
        "                    input_variables=['country'],\n",
        "                    output_variables=['capital','places'])\n",
        "chain.run(\"India\")"
      ],
      "metadata": {
        "id": "2lF-ZhammFJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chatmodels with ChatOpenAI**"
      ],
      "metadata": {
        "id": "pNEHGy4Vx_9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this help us to create conversational chatbot.\n",
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain.schema import AIMessage,HumanMessage,SystemMessage\n",
        "chatllm=ChatOpenAI(openai_api_key=os.environ[\"OPEN_AI_API_KEY\"],temperature=0.6,model='gpt-3.5-turbo')"
      ],
      "metadata": {
        "id": "Hwt5ag3mxXqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's create schema in a form of list\n",
        "chatllm([\n",
        "SystemMessage(content='You are a comedian AI assistant'),\n",
        "HumanMessage(content='Tell me a joke'),\n",
        "AIMessage(content='Why did the chicken cross the road?')\n",
        "])"
      ],
      "metadata": {
        "id": "6R2AdRMCzm6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt Template + LLM + Output Parsers**"
      ],
      "metadata": {
        "id": "8auNIzZr1BDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import ChatPromptTemplate\n",
        "from langchain.schema import BaseOutputParser\n",
        "\n",
        "class Commaseparatedoutput(BaseOutputParser):\n",
        "  def parse(self, text: str):\n",
        "      return text.strip().split(\",\")\n",
        "\n",
        "\n",
        "template='You are a helpful assistant.When the user gives any input, you should generate 5 words synonyms in a comma separated list.'\n",
        "human_template=\"{text}\"\n",
        "chatprompt=ChatPromptTemplate.from_messages([\n",
        "    (\"system\",template),\n",
        "    (\"human\",human_template)\n",
        "])"
      ],
      "metadata": {
        "id": "Nub6AKYZ0_z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# | it is showing chained up\n",
        "chain=chatprompt|chatllm|Commaseparatedoutput()\n",
        "chain.invoke({\"text\":\"intelligent\"}) # now this will show me 5 synonyms of intelligent"
      ],
      "metadata": {
        "id": "yXFXeoE73yz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create app.py file to deploy it on streamlit**"
      ],
      "metadata": {
        "id": "g-n4cp9-5aLC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "\n",
        "# create function to load OpenAI model to get response\n",
        "\n",
        "def get_openai_response(question):\n",
        "    llm=OpenAI(openai_api_=os.getenv(\"OPEN API KEY\"),key,model_name=\"text-davinci-003\",temperature=0.5)\n",
        "    llm_response=llm(question)\n",
        "    return llm_response\n",
        "\n",
        "# initialize our streamlit app\n",
        "\n",
        "st.set_page_config(page_title=\"Q&A Demo\")\n",
        "\n",
        "st.header(\"Langchain Aplication\")\n",
        "\n",
        "# capture input text\n",
        "\n",
        "input=st.text_input(\"Input: \",key=\"input\")\n",
        "response=get_openai_response(input)\n",
        "\n",
        "# create submit button\n",
        "\n",
        "submit=st.button(\"Ask the question\")\n",
        "\n",
        "# If ask button is clicked\n",
        "\n",
        "if submit:\n",
        "    st.subheader(\"The Response is\")\n",
        "    st.write(response)"
      ],
      "metadata": {
        "id": "EYjJ9ClO4ukD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}