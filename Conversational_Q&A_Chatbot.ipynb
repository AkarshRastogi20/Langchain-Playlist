{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Create app.py file**"
      ],
      "metadata": {
        "id": "EU1PKj5yue8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import all the necessary libraries\n",
        "\n",
        "!pip install streamlit\n",
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install streamlit_chat\n",
        "!pip install ChatOpenAI\n",
        "!pip install langchain_community\n",
        "!pip install dotenv\n",
        "!pip install load_dotenv\n",
        "import streamlit as st\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "from langchain_community import chat_models\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "# Streamlit UI Design\n",
        "\n",
        "st.set_page_config(page_title=\"Conversational Q&A Chatbot\")\n",
        "st.header(\"Hey,Let's Chat\")\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import os\n",
        "\n",
        "chat=ChatOpenAI(temperature=0.5) # once we will mention openai api key here this code will run.\n",
        "\n",
        "if 'flowmessages' not in st.session_state:\n",
        "    st.session_state['flowmessages']=[\n",
        "        SystemMessage(content=\"You are a comedian AI Assistent\")\n",
        "    ]\n",
        "\n",
        "# function to load OpenAI model and get responses\n",
        "\n",
        "def get_chatmodel_response(question):\n",
        "    # create session with st so that it can remember our convesation\n",
        "    st.session_state['flowmessages'].append(HumanMessage(content=question))\n",
        "    answer=chat(st.session_state['flowmessages'])\n",
        "    st.session_state['flowmessages'].append(AIMessage(content=answer.content))\n",
        "    return answer.content\n",
        "\n",
        "input=st.text_input(\"Input: \",key=\"input\")\n",
        "response=get_chatmodel_response(input)\n",
        "\n",
        "submit=st.button(\"Ask th question\")\n",
        "\n",
        "# If ask button is clicked\n",
        "\n",
        "if submit:\n",
        "  st.subheader('The Response is')\n",
        "  st.write(response)\n",
        "\n",
        "\n",
        "\n",
        "response=llm(question)\n",
        "return response"
      ],
      "metadata": {
        "id": "QWWW0feZ3nTE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}